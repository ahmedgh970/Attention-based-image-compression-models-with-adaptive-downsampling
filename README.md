# Transformer-based Image Compression Codec with Adaptative Sampling
Implementation of our proposed Transformer-based image compression codec with adaptative sampling.
Paper link on [Transformer-based Image Compression Codec with Adaptative Sampling](Coming soon)

## Coming Soon...

* [Transformers_Unsupervised_Anomaly_Segmentation](#Transformers_Unsupervised_Anomaly_Segmentation)
  * [Requirements](#requirements)
  * [Folder Structure](#folder-structure)
  * [CLI-Usage](#cli-usage)
  * [Disclaimer](#disclaimer)
  * [Reference](#reference)
  * [License](#license)
    
<!-- /code_chunk_output -->


## Tags
<code>Transformers</code>, <code>Adaptative Sampling</code>, <code>Learning-based Codecs</code>, <code>Image Compression</code>, <code>TensorFlow</code>


## Requirements
* <code>Python >= 3.6</code>

All packages used in this repository are listed in [requirements.txt](https://github.com/ahmedgh970/Transformer-based-image-compression-codec-with-adaptative-sampling/requirements.txt).
To install those, run:
```
pip install -r requirements.txt
```


## Folder Structure
  ```
  Transformer-based-image-compression-codec-with-adaptative-sampling/
  │
  ├── data/
  │   └── data.txt  - datasets descriptions and download link
  │
  ├── models/ - Models defining, training and evaluating
  │
  ├── ckpts/  - Checkpoints folder
  │
  └── scripts/ - small utility scripts
      ├── utils.py
      └── ...    
  ```

## CLI Usage
Every model can be trained and tested individually using the scripts which are provided in the `models/*` folders.

## Disclaimer
Please do not hesitate to open an issue to inform of any problem you may find within this repository.

## Reference

## License
This project is licensed under the MIT License. See LICENSE for more details
